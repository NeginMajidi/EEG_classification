{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import h5py\n",
    "from scipy import signal\n",
    "import _pickle as pkl\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import math\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['Age6-9', 'Age10-11', 'Age12-13', 'Age14-17', 'Age18-24', 'Age25-44']\n",
    "dataset = {'Age6-9':{}, 'Age10-11':{}, 'Age12-13':{}, 'Age14-17':{}, 'Age18-24':{}, 'Age25-44':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'D:\\Jason\\train_999'\n",
    "test_dir = r'D:\\Jason\\test_999'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset as indiviual frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(1, 1000)\n",
    "delay = 0.25\n",
    "frame = np.around(24 * (50 * n / 500))\n",
    "for i in range(frame.shape[0]):\n",
    "    if frame[i]<300:\n",
    "        frame[i] = 0\n",
    "    elif frame[i]>=300 and frame[i]<419:\n",
    "        frame[i] = 1\n",
    "    elif frame[i]>=419 and frame[i]<666:\n",
    "        frame[i] = 0\n",
    "    elif frame[i]>=666 and frame[i]<781:\n",
    "        frame[i] = 1\n",
    "    elif frame[i]>=781 and frame[i]<978:\n",
    "        frame[i] = 0\n",
    "    elif frame[i]>=978 and frame[i]<1085:\n",
    "        frame[i] = 1\n",
    "    elif frame[i]>=1085 and frame[i]<1509:\n",
    "        frame[i] = 0\n",
    "    elif frame[i]>=1509 and frame[i]<2096:\n",
    "        frame[i] = 1\n",
    "    elif frame[i]>=2096:\n",
    "        frame[i] = 0\n",
    "\n",
    "y = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'D:\\Jason'\n",
    "dataset_dir = os.path.join(DATA_DIR, 'Dataset2')\n",
    "dataset_file_name = os.path.join(dataset_dir, 'dataset.pkl')\n",
    "with open(dataset_file_name, 'rb') as fp:\n",
    "    dataset = pkl.load(fp)\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(test_dir)\n",
    "np.random.seed(0)\n",
    "ages = ['Age6-9', 'Age10-11', 'Age12-13', 'Age14-17', 'Age18-24', 'Age25-44']\n",
    "data_size = 75\n",
    "train_data, test_data = [], []\n",
    "train_idxs = np.random.choice(data_size, int(0.8 * data_size), replace=False)\n",
    "data_idx = 0\n",
    "i = 0\n",
    "for age in ages:\n",
    "    i = 0\n",
    "    for patient_key in dataset[age]:\n",
    "        i = i+1\n",
    "        if data_idx in train_idxs:\n",
    "            train_data.append(dataset[age][patient_key])\n",
    "        else:\n",
    "            test_data.append(dataset[age][patient_key])\n",
    "        try:\n",
    "            assert(dataset[age][patient_key].shape==(999,111,129))\n",
    "        except:\n",
    "            print(age, i, dataset[age][patient_key].shape, patient_key)\n",
    "        data_idx += 1\n",
    "del dataset\n",
    "labels = []\n",
    "for i, patient_data in enumerate(train_data):\n",
    "    print('train', i)\n",
    "    patient_data[:, :, :10]=0\n",
    "    patient_data = (patient_data - np.min(patient_data))/(np.max(patient_data)-np.min(patient_data))\n",
    "    for j, image in enumerate(patient_data):\n",
    "        image = (np.stack([image]*3, -1) * 255).astype(np.uint8)\n",
    "        save_dir = '{}_{}.png'.format(str(i).zfill(2), str(j).zfill(4))\n",
    "        imageio.imsave(os.path.join(train_dir, save_dir), image)\n",
    "        labels.append(y[j])\n",
    "open(os.path.join(train_dir, 'labels.txt'), 'w').write(','.join(np.array(labels).astype(str)))\n",
    "labels = [] \n",
    "for i, patient_data in enumerate(test_data):\n",
    "    patient_data[:, :, :10]=0\n",
    "    patient_data = (patient_data - np.min(patient_data))/(np.max(patient_data)-np.min(patient_data))\n",
    "    print('test', i)\n",
    "    for j, image in enumerate(patient_data):\n",
    "        image = (np.stack([image]*3, -1) * 255).astype(np.uint8)\n",
    "        save_dir = '{}_{}.png'.format(str(i).zfill(2), str(j).zfill(4))\n",
    "        imageio.imsave(os.path.join(test_dir, save_dir), image)\n",
    "        labels.append(y[j])\n",
    "open(os.path.join(test_dir, 'labels.txt'), 'w').write(','.join(np.array(labels).astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_train = np.array([os.path.join(train_dir, i) for i in os.listdir(train_dir) if i[-4:]=='.png'])\n",
    "dirs_test = np.array([os.path.join(test_dir, i) for i in os.listdir(test_dir) if i[-4:]=='.png'])\n",
    "y_train = np.array(open(os.path.join(train_dir, 'labels.txt')).read().split(',')).astype(float).astype(int)\n",
    "y_oh = np.zeros((len(y_train), 2)).astype(int)\n",
    "y_oh[np.arange(len(y_oh)), y_train] = 1\n",
    "y_test = np.array(open(os.path.join(test_dir, 'labels.txt')).read().split(',')).astype(float).astype(int)\n",
    "y_oh_test = np.zeros((len(y_test), 2)).astype(int)\n",
    "y_oh_test[np.arange(len(y_oh_test)), y_test] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fn(path):\n",
    "    x = tf.io.read_file(path)\n",
    "    x = tf.io.decode_png(x, channels=3)\n",
    "    x = tf.reshape(x, (111, 129, 3))\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_X = tf.data.Dataset.from_tensor_slices(dirs_train)\n",
    "d_y = tf.data.Dataset.from_tensor_slices(y_oh)\n",
    "d_X = d_X.map(load_fn)\n",
    "train_data = tf.data.Dataset.zip((d_X, d_y))\n",
    "train_data = train_data.shuffle(100)\n",
    "train_data = train_data.repeat()\n",
    "train_data = train_data.batch(64, drop_remainder=True)\n",
    "d_X_test = tf.data.Dataset.from_tensor_slices(dirs_test)\n",
    "d_X_test = d_X_test.map(load_fn)\n",
    "d_y_test = tf.data.Dataset.from_tensor_slices(y_oh_test)\n",
    "test_data = tf.data.Dataset.zip((d_X_test, d_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "ages = ['Age6-9', 'Age10-11', 'Age12-13', 'Age14-17', 'Age18-24', 'Age25-44']\n",
    "data_size = 75\n",
    "train_data, test_data = [], []\n",
    "train_idxs = np.random.choice(data_size, int(0.8 * data_size), replace=False)\n",
    "data_idx = 0\n",
    "i = 0\n",
    "for age in ages:\n",
    "    i = 0\n",
    "    for patient_key in dataset[age]:\n",
    "        i = i+1\n",
    "        if data_idx in train_idxs:\n",
    "            train_data.append(dataset[age][patient_key])\n",
    "        else:\n",
    "            test_data.append(dataset[age][patient_key])\n",
    "        try:\n",
    "            assert(dataset[age][patient_key].shape==(999,111,129))\n",
    "        except:\n",
    "            print(age, i, dataset[age][patient_key].shape, patient_key)\n",
    "        data_idx += 1\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "counter = 0\n",
    "while train_data:\n",
    "    x = train_data.pop(0)\n",
    "    windows = x.shape[0]\n",
    "    for i in range(windows):\n",
    "        X_train.append((x[i] - x[i].min())/(x[i].max() - x[i].min()))\n",
    "        y_train.append(y[i])\n",
    "while test_data:\n",
    "    x = test_data.pop(0)\n",
    "    windows = x.shape[0]\n",
    "    for i in range(windows):\n",
    "        X_test.append((x[i] - x[i].min())/(x[i].max() - x[i].min()))\n",
    "        y_test.append(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0: 'Human', 1: 'Logic'}\n",
    "for each_x in X_train:\n",
    "    try:\n",
    "        assert(each_x.shape==(111,129))\n",
    "    except:\n",
    "        print(each_x.shape)\n",
    "for each_x in X_test:\n",
    "    try:\n",
    "        assert(each_x.shape==(111,129))\n",
    "    except:\n",
    "        print(each_x.shape)\n",
    "assert(len(X_train)==len(y_train))\n",
    "assert(len(X_test)==len(y_test))\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_train = np.random.permutation(len(X_train))\n",
    "per_test = np.random.permutation(len(X_test))\n",
    "X_train = X_train[per_train]\n",
    "y_train = y_train[per_train]\n",
    "X_test = X_test[per_test]\n",
    "y_test = y_test[per_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input\n",
    "# vgg_model = tf.keras.applications.vgg16.VGG16(input_tensor = Input(shape=(111, 129, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "with tf.device('/gpu:0'):\n",
    "    print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(111, 129, 3))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(input_layer)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 4, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.vgg19.VGG19(input_shape=(111, 129, 3), include_top=False, weights='imagenet')\n",
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(111, 129, 3), include_top=False, weights='imagenet')\n",
    "input_layer = tf.keras.layers.Input(shape=(111, 129, 3))\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "model = tf.keras.Sequential([input_layer, base_model, tf.keras.layers.GlobalAveragePooling2D(), output_layer])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=30, steps_per_epoch=1000, validation_data=test_data, validation_steps=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python negin",
   "language": "python",
   "name": "negin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
